I",<h4 id="摘要"><strong>摘要</strong></h4>
<p>在计算语言学的领域里，生成语法(generative grammar)是重要的研究的方向之一。
生成语法的主要目标是让程序可以自动判定一句话的语法正确性(grammatical)，
在给出判断的同时，生成语法也可以对被判定的句子进行句法分析(syntactic parsing)和附带的基本的语义分析(semantic parsing)。
在深度学习主宰自然语言处理界的今天，
计算语言学和生成语法所代表的符号主义(symbolism)已经不再具有可以独立挑战深度学习的可能性，
但符号主义所拥有的优势恰恰是深度学习所缺失的。
本篇不讨论这些具体的优势是什么，或者如何结合这两者，
但会用一个叫中心词驱动短语结构语法(HPSG: Head-Driven Phrase Structure Grammar)的生成语法来简单介绍符号主义视角下的语言理解方案。</p>

<h4 id="资料引用"><strong>资料引用</strong></h4>
<p>[1] <a href="https://web.stanford.edu/group/cslipublications/cslipublications/site/1575864002.shtml" target="_blank">Syntax theory: a formal introduction</a><br />
[2] <a href="http://moin.delph-in.net/FrontPage" target="_blank">DELPH-IN</a><br /></p>

<h4 id="生成语法"><strong>生成语法</strong></h4>
<p>生成语法的分支有不少，最早也是最出名的是由乔姆斯基(chomsky)提出的转换生成语法(transformational grammar)。
而后续的发展使得生成语法出现了分支，一种以减轻规则数量而把语言的惯例(conventions)和限制(constraints)下放到词典(lexicon)的思路逐渐诞生，
HPSG也是这种词汇化(lexicalized)思路下发展出来的语法。
虽然对于计算语言学的研究者们来说，这些分支的区别很大，但对计算机科学背景的研究者来讲，这些区别并不重要，所有的生成语法都是可以用程序语言描述的，而恰好HPSG则是这其中有相对完善的软件支持的语法[2]。</p>

<h4 id="lexicon"><strong>Lexicon</strong></h4>

<center><img src="../assets/p11/hand.JPG" title="interpolations" height="300" /></center>

<p>Lexicon包含了HPSG中绝大部分的和语言惯例和语法限制信息，以上图的动词hand为例，这样的一个结构被称为lexical entry，
每一个lexical entry都包含了3样重要的信息：syntax(SYN)，argument-structure (ARG-ST)和semantics (SEM)。<br /><br /></p>

<p>其中SYN用来记录这个词的基本属性，例如词性，单复数，时态等等，
而specifier(SPR)和complements(COMPS)则是同个句子对这个词产生影响的前后的词(specifier为前，complements为后)。
在这个例子中，动词hand由于受到英语subject verb agreement的影响，其单复数形式会和自己的主语一致(第三人称主语用hands)。
而单复数之类的信息，是包含了在了agreement(AGR)里边的，所以hand要求自己的agreement和specifier的agreement保持一致。
在HPSG，描述这样的限制是靠两个相同的索引完成的([6])，这样的索引可以放置在任何结构和任何位置。<br /><br /></p>

<p>而ARG-ST则是用来描述这个词在句子里完整而且必要语境，其作用和语言模型非常类似。
例如动词give：[somebody] give [something] [to somebody]，give的ARG-ST可以要求第二个complement必须是一个以to开头的名词短语。
一般来说，ARG-ST可以被拆分成SYN里的specifier和complements，
但在long term dependency的情况下，specifier或者complements可以被省略掉，如果省略掉的部分已经在之前出现过。
这个现象在很多语言都存在，举一个中文的例子：[我]信得过[这个人]，信得过的specifier是[我]，complements是[这个人]。
但在long term dependency的现象下，complements可以被移到前面：[这个人]，[我]信得过。
在HPSG里，如果specifier或者complements有缺失，缺失的短语将被登记到一个叫gap的值上，等处理到拥有更大视野的时候，HPSG才会把这个gap值补上。
所以specifier，complements和gap可以完整地描述ARG-ST，即一个词必要的语境，这个语境在任何可以接受这个词的句子都必须存在。
<br /><br /></p>

<p>而最后的一部分信息则是对自然语言处理最重要的SEM，以上面的lexical entry为例子，hand这个动作涉及到三个实体：hander，recipient和handed。
而ARG-ST则决定了这三个实体在语境中的顺序,比如[I] hand [the baby] [a toy], 
这里的[I]是hander, [the baby] 是 recipient，而[a toy]则是handed。
在HPSG的设计中，如果ARG-ST的值可以在一个句子中被推导出来，那么实体之间的关系自然也就可以被准确地描述出来，
用计算语言学家的话来说：syntax are scaffolds for semantics。</p>

<h4 id="lexicon-rule"><strong>Lexicon Rule</strong></h4>

<p>为了让同一个词适应不同的语态，时态和语境，HPSG有不同的lexical rule来对词素(lexeme)或者词(word)进行转变。</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Derivational Rules: 词素到词素的转变,在inflection rule之前可以转变多次
Inflectional Rule: 从词素到词转换，一个词只能有一次inflection rule转变
Post Inflectional Rule：一般用于调整词的语境来应对一些语言现象，例如inversion(did变成didn't)
</code></pre></div></div>

<center><img src="../assets/p11/passive_rule.JPG" title="interpolations" height="200" /></center>

<p>一个简单的例子是被动语态(passive voice)，为了让动词hand适应被动语态的句子，
上图的derivational rule可以把一个词的ARG-ST里的实体变换顺序，然后再给主语加上一个介词by。
这样一来：[I] hand [the baby] [a toy] 就可以变成 [the baby] was handed [a toy] [by me]。
下图是被动语态规则的输入（左）与输出（右），注意只有ARG-ST也就是语境变了，SYN和SEM都不变，
这个规则可以适用于所有的transitive verb，也就是及物动词。</p>

<center>
<img src="../assets/p11/hand.JPG" title="interpolations" height="250" />
<img src="../assets/p11/handed.JPG" title="interpolations" height="300" />
</center>

<p>与计算机科学里的面向对象编程类似，一个lexical entry一般都是继承自一个更笼统的父类，有些父类的信息只能被继承，有些则可以被改写。
而一个完全把所有信息都列出来的lexical entry叫做lexical sequence。</p>

<h4 id="grammar-rule"><strong>Grammar Rule</strong></h4>

<h4 id="head-daughter"><strong>Head Daughter</strong></h4>

<h4 id="总结"><strong>总结</strong></h4>
:ET